{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=1000)\n",
    "np.set_printoptions(threshold=5000)\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "import pycolmap\n",
    "\n",
    "import trimesh\n",
    "from python_utils import *\n",
    "from navi import transformations\n",
    "import blender_plots as bplt\n",
    "\n",
    "orange1 = hex_to_rgb(0xff9a00)\n",
    "orange2 = hex_to_rgb(0xff5d00)\n",
    "blue1 = hex_to_rgb(0x00a2ff)\n",
    "blue2 = hex_to_rgb(0x0065ff)\n",
    "\n",
    "ydown2zup = np.array([\n",
    "    [0, 0, 1, 0],\n",
    "    [-1, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "])\n",
    "yup2zup = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, -1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "])\n",
    "\n",
    "def umeyama(X, Y):\n",
    "    # https://github.com/clementinboittiaux/umeyama-python\n",
    "    mu_x = X.mean(axis=1).reshape(-1, 1)\n",
    "    mu_y = Y.mean(axis=1).reshape(-1, 1)\n",
    "    var_x = np.square(X - mu_x).sum(axis=0).mean()\n",
    "    cov_xy = ((Y - mu_y) @ (X - mu_x).T) / X.shape[1]\n",
    "    U, D, VH = np.linalg.svd(cov_xy)\n",
    "    S = np.eye(X.shape[0])\n",
    "    if np.linalg.det(U) * np.linalg.det(VH) < 0:\n",
    "        S[-1, -1] = -1\n",
    "    c = np.trace(np.diag(D) @ S) / var_x\n",
    "    R = U @ S @ VH\n",
    "    t = mu_y - c * R @ mu_x\n",
    "    return c, R, t\n",
    "\n",
    "def get_navi_transform(camera_info):\n",
    "    T = transformations.quaternion_to_rotation_matrix(camera_info['q']).numpy()\n",
    "    T[:3, -1] = camera_info['t']\n",
    "    T = np.linalg.inv(T)\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Navi dataset as described here https://github.com/google/navi\n",
    "\n",
    "and run the downsampling script from probe3d https://github.com/mbanani/probe3d/blob/main/data_processing/resize_navi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "navi_dir = Path('/home/linus/workspace/data/navi_v1/') # update to match navi dataset location\n",
    "with open(navi_dir / 'custom_splits/single_image_3d/objects-val.txt') as split_file:\n",
    "    val_objects = split_file.readlines()\n",
    "    val_objects = [s.rstrip('\\n') for s in val_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_name = val_objects[0]\n",
    "input_dir = Path(glob.glob(str(navi_dir / object_name / \"multiview_*\"))[0])\n",
    "\n",
    "object_name = 'schleich_lion_action_figure'\n",
    "object_dir = navi_dir / object_name\n",
    "input_dir = object_dir / 'multiview_08_canon_t4i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('outputs')\n",
    "image_dir = input_dir / 'images'\n",
    "image_paths = sorted([f for f in os.listdir(image_dir) if (f[-4:] == '.jpg') and ('downsampled' in f)])\n",
    "database_path = output_path / f\"{object_name}_database.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path.parent.mkdir(exist_ok=True)\n",
    "if database_path.exists():\n",
    "    os.remove(database_path)\n",
    "\n",
    "pycolmap.extract_features(\n",
    "    database_path,\n",
    "    image_dir,\n",
    "    image_list=image_paths,\n",
    "    sift_options=pycolmap.SiftExtractionOptions(\n",
    "        estimate_affine_shape=True,\n",
    "        domain_size_pooling=True,\n",
    "    ),\n",
    "    reader_options=pycolmap.ImageReaderOptions()\n",
    ")\n",
    "pycolmap.match_exhaustive(\n",
    "    database_path,\n",
    "    sift_options=pycolmap.SiftMatchingOptions(\n",
    "        guided_matching=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "pipeline_options = pycolmap.IncrementalPipelineOptions()\n",
    "maps = pycolmap.incremental_mapping(database_path, image_dir, output_path, pipeline_options)\n",
    "reconstruction = maps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_json(input_dir / \"annotations.json\")\n",
    "gt_mesh = trimesh.load(object_dir / f'3d_scan/{object_name}.obj')\n",
    "\n",
    "T_colmap = np.array([\n",
    "    np.vstack([image.cam_from_world.inverse().matrix(), [0, 0, 0, 1]])\n",
    "    for image in reconstruction.images.values()\n",
    "])\n",
    "T_gt = np.array([\n",
    "    get_navi_transform(get_df_single(annotations, filename=image.name.lstrip('downsampled_')).camera)\n",
    "    for image in reconstruction.images.values()\n",
    "])\n",
    "T_normalize = np.block([\n",
    "    np.eye(3),\n",
    "])\n",
    "gt_mean = T_gt[:, :3, -1].mean(axis=0)\n",
    "gt_max = (T_gt[:, :3, -1] - gt_mean).max()\n",
    "T_normalize = np.block([\n",
    "    [np.eye(3) / gt_max, -gt_mean[:, None] / gt_max],\n",
    "    [0, 0, 0, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_align, R_align, t_align = umeyama(T_colmap[:, :3, -1].T, T_gt[:, :3, -1].T)\n",
    "T_align = np.block([\n",
    "    [R_align * s_align, t_align],\n",
    "    [0, 0, 0, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bplt.Scatter(\n",
    "    (yup2zup @ T_normalize @ (T_align @ T_colmap))[:, :3, -1],\n",
    "    color=orange1,\n",
    "    marker_scale=0.006,\n",
    "    name='colmap',\n",
    ")\n",
    "bplt.Scatter(\n",
    "    (yup2zup @ T_normalize @ T_gt)[:, :3, -1],\n",
    "    color=blue1,\n",
    "    marker_scale=0.006,\n",
    "    name='gt',\n",
    ")\n",
    "bplt.Arrows(\n",
    "    (yup2zup @ T_normalize @ (T_align @ T_colmap))[:, :3, -1],\n",
    "    end=(yup2zup @ T_normalize @ T_gt)[:, :3, -1],\n",
    "    radius=0.002,\n",
    "    head_length=0.01\n",
    ")\n",
    "bplt.blender_utils.new_mesh(\n",
    "    np.einsum('ij,...j->...i', yup2zup[:3] @ T_normalize, np.hstack([gt_mesh.vertices, np.ones((len(gt_mesh.vertices), 1))])),\n",
    "    gt_mesh.faces\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_transform(colmap_pose):\n",
    "    return np.block([\n",
    "        [colmap_pose.matrix()],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "points = np.array([yup2zup @ T_normalize @ T_align @ np.array([*p.xyz, 1]) for p in reconstruction.points3D.values()])[..., :-1]\n",
    "colors = np.array([p.color for p in reconstruction.points3D.values()]) / 255\n",
    "\n",
    "bplt.Scatter(points, color=colors, radius=0.002, marker_type='ico_spheres')\n",
    "\n",
    "R_gt = np.array([*annotations.camera.apply(lambda c: transformations.quaternion_to_rotation_matrix(c['q'])[:3, :3].numpy())])\n",
    "t_gt = np.array([*annotations.camera.apply(lambda c: np.array(c['t']))])\n",
    "mean_gt = t_gt.mean(axis=0)\n",
    "\n",
    "for i, image in reconstruction.images.items():\n",
    "    camera = reconstruction.cameras[image.camera_id]\n",
    "    colmap_pose = yup2zup @ T_normalize @ T_align @ to_transform(image.cam_from_world.inverse())\n",
    "    bplt.Scatter(\n",
    "        colmap_pose[:3, -1],\n",
    "        marker_rotation=colmap_pose[:3, :3],\n",
    "        marker_type=bplt.marker_utils.get_frustum(\n",
    "            intrinsics=camera.calibration_matrix(),\n",
    "            height=camera.height, width=camera.width,\n",
    "            image_depth=.1,\n",
    "            color=orange1,\n",
    "            color_fill=orange2,\n",
    "            name=f'camera_{i}',\n",
    "            thickness=0.01,\n",
    "        ),\n",
    "        name=f'camera_{i}',\n",
    "    )\n",
    "\n",
    "    gt_info = get_df_single(annotations, filename=image.name.lstrip('downsampled_'))\n",
    "    gt_intrinsics = np.array([\n",
    "        [gt_info.camera['focal_length'], 0, gt_info.image_size[1] / 2],\n",
    "        [0, gt_info.camera['focal_length'], gt_info.image_size[0] / 2],\n",
    "        [0, 0, 1],\n",
    "    ])\n",
    "    gt_pose = yup2zup @ T_normalize @ get_navi_transform(gt_info.camera)\n",
    "    bplt.Scatter(\n",
    "        gt_pose[:3, -1],\n",
    "        marker_rotation=gt_pose[:3, :3],\n",
    "        marker_type=bplt.marker_utils.get_frustum(\n",
    "            intrinsics=gt_intrinsics,\n",
    "            height=gt_info.image_size[0], width=gt_info.image_size[1],\n",
    "            image_depth=.1,\n",
    "            color=blue1,\n",
    "            color_fill=blue2,\n",
    "            name=f'gt_camera_{i}',\n",
    "            thickness=0.01,\n",
    "        ),\n",
    "        name=f'gt_camera_{i}',\n",
    "    )\n",
    "\n",
    "missing_images = [\n",
    "    image_path for image_path in image_paths\n",
    "    if image_path not in [image.name for image in reconstruction.images.values()]\n",
    "]\n",
    "for i, image_path in enumerate(missing_images):\n",
    "    gt_info = get_df_single(annotations, filename=image_path.lstrip('downsampled_'))\n",
    "    gt_intrinsics = np.array([\n",
    "        [gt_info.camera['focal_length'], 0, gt_info.image_size[1] / 2],\n",
    "        [0, gt_info.camera['focal_length'], gt_info.image_size[0] / 2],\n",
    "        [0, 0, 1],\n",
    "    ])\n",
    "    gt_pose = yup2zup @ T_normalize @ get_navi_transform(gt_info.camera)\n",
    "    bplt.Scatter(\n",
    "        gt_pose[:3, -1],\n",
    "        marker_rotation=gt_pose[:3, :3],\n",
    "        marker_type=bplt.marker_utils.get_frustum(\n",
    "            intrinsics=gt_intrinsics,\n",
    "            height=gt_info.image_size[0], width=gt_info.image_size[1],\n",
    "            image_depth=.1,\n",
    "            color=blue1,\n",
    "            color_fill=blue2,\n",
    "            name=f'failed_gt_camera_{i}',\n",
    "            thickness=0.01,\n",
    "        ),\n",
    "        name=f'failed_gt_camera_{i}',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: Total files 0 | Changed 0 | Failed 0\n",
      "Info: Saved \"output.blend\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FINISHED'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bpy\n",
    "bpy.ops.wm.save_as_mainfile(filepath=str(Path(os.getcwd()) / 'output.blend'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender-colmap",
   "language": "python",
   "name": "blender-colmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
